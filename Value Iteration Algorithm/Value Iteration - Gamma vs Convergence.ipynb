{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nValue Iteration Algorithm v.2\\n\\nDifferences include:\\n    modifications to simulate that pacman and the ghost both move simultaneously in the game:\\n        - adjusted the calculate_reward function\\n        - adjusted the transition probability matrix (also calculates the ghost's next move now)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Value Iteration Algorithm v.2\n",
    "\n",
    "Differences include:\n",
    "    modifications to simulate that pacman and the ghost both move simultaneously in the game:\n",
    "        - adjusted the calculate_reward function\n",
    "        - adjusted the transition probability matrix (also calculates the ghost's next move now)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Enumerate states for a 3x3 grid ==> 81 states \n",
    "(9 choices for pacman location x 9 choices for ghost location)\n",
    "\n",
    "y    _0_|_1_|_2_\n",
    "|    _3_|_4_|_5_\n",
    "v     6 | 7 | 8\n",
    "    x -->\n",
    "\n",
    "Each x,y pair represented as an integer number corresponding to the diagram above\n",
    "'''\n",
    "\n",
    "states_num = [];\n",
    "\n",
    "for s in range(81):\n",
    "    for p in range(9):\n",
    "        for g in range(9):\n",
    "            states_num.append( (p, g) )\n",
    "                    \n",
    "#for s in range(81):\n",
    "#    print(\"state \", s, \": \", states_num[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PacmanEnv:\n",
    "    '''\n",
    "    Class to initialize and store information about the Pacman environment for program planning algorithms.\n",
    "\n",
    "    Properties:\n",
    "        P[s][a] is a list of is a list of transition tuples (prob, next_state, reward, done)\n",
    "        num_states = number of states (set to default for 3x3 grid)\n",
    "        num_actions = number of actions (set to 4)\n",
    "        pellet_loc = location of pellet (set to 2, i.e. [2,0] by default)\n",
    "\n",
    "    Methods:\n",
    "        return_state: Returns state number given location of pacman and the ghost\n",
    "        move: Moves pacman given current location and action input. Returns grid location number\n",
    "        calculate_reward: Returns reward for current location of pacman. Used to evaluate R(s,a,s') by \n",
    "                        first determining s' through move(s,a), then calculating the reward at s'.\n",
    "        grid_to_xy: Returns corresponding (x,y) coordinate pair for valid grid location integer input\n",
    "                    If number out of range, returns 'invalid entry' error message\n",
    "        xy_to_grid: Returns corresponding grid location # for given (x,y) coordinate pair input\n",
    "                    If number out of range, returns 'invalid entry' error message\n",
    "    '''\n",
    "\n",
    "    def __init__(self, states=states_num, num_states=81, num_actions=4, pellet_loc=2):\n",
    "        self.states = states\n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        self.pellet_loc = pellet_loc\n",
    "        \n",
    "        P = {s : {a : [] for a in range(num_actions)} for s in range(num_states)}\n",
    "\n",
    "        def grid_to_xy(number):\n",
    "            switch = {\n",
    "                0: [0,0],\n",
    "                1: [1,0],\n",
    "                2: [2,0],\n",
    "                3: [0,1],\n",
    "                4: [1,1],\n",
    "                5: [2,1],\n",
    "                6: [0,2],\n",
    "                7: [1,2],\n",
    "                8: [2,2]\n",
    "            }\n",
    "            return switch.get(number, \"invalid entry\")\n",
    "        \n",
    "        def xy_to_grid(x,y):\n",
    "            switch = {\n",
    "                0: {0:0, 1:3, 2:6},\n",
    "                1: {0:1, 1:4, 2:7},\n",
    "                2: {0:2, 1:5, 2:8}\n",
    "            }\n",
    "            x = switch.get(x,\"invalid entry\")\n",
    "\n",
    "            if x == \"invalid entry\":\n",
    "                return x\n",
    "            else:\n",
    "                return x.get(y,\"invalid entry\")\n",
    "        \n",
    "        def return_state(p, g):\n",
    "            return states.index( (p,g) )\n",
    "        \n",
    "        def move(x, y, action):\n",
    "            if action == UP:\n",
    "                y = max(0, y-1)\n",
    "            elif action == RIGHT:\n",
    "                x = min(2, x+1)\n",
    "            elif action == DOWN:\n",
    "                y = min(2, y+1)\n",
    "            elif action == LEFT:\n",
    "                x = max(0, x-1)\n",
    "            return xy_to_grid(x, y)\n",
    "        \n",
    "        # parameters must be of the same type, i.e. [x,y] or int value 0-8\n",
    "        # need to adjust to include reward definition for bumping into walls\n",
    "        def calculate_reward(pacman_new_loc, ghost_new_loc, ghost_current_loc, pellet_location):\n",
    "            if pacman_new_loc == ghost_current_loc: # pacman moved to the ghost's location\n",
    "                return -1000\n",
    "            elif pacman_new_loc == pellet_location:\n",
    "                return 1000\n",
    "            elif pacman_new_loc == ghost_new_loc: # the ghost moved to pacman's new location\n",
    "                return -1000\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "        for s in range(num_states):\n",
    "            for pacman_a in range(num_actions):\n",
    "                done = False # flag to signal game has ended\n",
    "                temp = P[s][pacman_a]\n",
    "                pacman_grid_loc = states[s][0] # for the given state, where is pacman\n",
    "                ghost_grid_loc = states[s][1] # in the given state, where is the ghost\n",
    "                \n",
    "                # if pacman performs action a: 0=UP, 1=RIGHT, 2=DOWN, 3=LEFT\n",
    "                [x_p, y_p] = grid_to_xy(pacman_grid_loc)\n",
    "                next_pacman_loc = move(x_p, y_p, pacman_a) # grid location he will move to\n",
    "                \n",
    "                for ghost_a in range(num_actions):\n",
    "                    # if the ghost performs action a: 0=UP, 1=RIGHT, 2=DOWN, 3=LEFT\n",
    "                    [x_g, y_g] = grid_to_xy(ghost_grid_loc)\n",
    "                    next_ghost_loc = move(x_g, y_g, ghost_a) # grid location he will move to\n",
    "                    \n",
    "                    # resulting next state, simulates pacman and the ghost moving simultaneously\n",
    "                    next_state = return_state(next_pacman_loc, next_ghost_loc) \n",
    "                    reward = calculate_reward(next_pacman_loc, next_ghost_loc, ghost_grid_loc, pellet_loc) # calculate the reward at this state\n",
    "\n",
    "                    if (pacman_grid_loc == pellet_loc or pacman_grid_loc == ghost_grid_loc):\n",
    "                        done = True\n",
    "\n",
    "                    temp.append( (0.25, next_state, reward, done) )\n",
    "        \n",
    "        self.P = P\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env=PacmanEnv(), gamma=0.5, theta=1e-5):\n",
    "    '''\n",
    "    Value Iteration Algorithm\n",
    "\n",
    "    Inputs:\n",
    "        env: PacmanEnv as defined in class above.\n",
    "        gamma: Discount rate for future rewards.\n",
    "        theta: Stopping criterion value. When change in Value function is less than theta for every state, stop.\n",
    "\n",
    "    Helper Methods:\n",
    "        calculate_action_values: Calculates the values for all actions for a given state.\n",
    "                                Returns a vector action_values of length num_actions, where \n",
    "                                action_values[a] = expected value of action a.\n",
    "                                The expected value is calculated according to the Bellman equation:\n",
    "                                V(s) = P(s'|s,a) * ( R(s,a) + (gamma * V(s')) )\n",
    "        extract_policy: Returns the optimal policy for a given value function. It is run once at the end of the algorithm\n",
    "                        after the optimal V (value function) has been calculated.\n",
    "\n",
    "    Outputs:\n",
    "        A tuple (policy, V, steps) of the optimal policy, the approximated optimal value function, and the number of steps\n",
    "        the algorithm took to converge.\n",
    "    '''\n",
    "    \n",
    "    def calculate_action_values(current_state, V):\n",
    "        action_values = np.zeros(env.num_actions)\n",
    "        for a in range(env.num_actions):\n",
    "            for prob, next_state, reward, done in env.P[current_state][a]:\n",
    "                action_values[a] += prob * (reward + (gamma * V[next_state]))\n",
    "        return action_values\n",
    "    \n",
    "    def extract_policy(V):\n",
    "        policy = np.zeros([env.num_states, env.num_actions])\n",
    "        \n",
    "        for s in range(env.num_states):\n",
    "            action_values = calculate_action_values(s, V)\n",
    "            best_action = np.argmax(action_values) # returns index of action that has maximum V\n",
    "            policy[s, best_action] = 1 # deterministic optimal policy, i.e. always take best_action for given state\n",
    "        \n",
    "        return policy\n",
    "    \n",
    "    V = np.zeros(env.num_states) # arbitrarily initialize vector V to be all zeros\n",
    "    converged = False\n",
    "    steps = 0\n",
    "    \n",
    "    # iteratively calculate optimal V\n",
    "    while ~converged:\n",
    "        # print('Value iteration, step ', steps, '...')\n",
    "        delta = 0\n",
    "        for s in range(env.num_states):\n",
    "            action_values = calculate_action_values(s, V)\n",
    "            max_action_value = np.max(action_values)\n",
    "            delta = max( delta, np.abs(max_action_value - V[s]) ) # the maximum difference between V'(s) and V(s) for all s\n",
    "            V[s] = max_action_value        \n",
    "        \n",
    "        steps += 1\n",
    "        \n",
    "        #print('Delta: ', delta)\n",
    "        converged = (delta < theta)\n",
    "        #print(converged)\n",
    "    \n",
    "    # extract optimal policy after calculating optimal V\n",
    "    policy = extract_policy(V)\n",
    "    \n",
    "    print('Completed algorithm')\n",
    "    return policy, V, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "Completed algorithm\n",
      "[7, 9, 10, 11, 13, 14, 15, 17, 19, 21, 24, 28, 32, 38, 46, 58, 78, 119, 240]\n"
     ]
    }
   ],
   "source": [
    "# intervals of 0.05\n",
    "# note: algo runs for a long time if gamma=0 or 1\n",
    "gammas = np.arange(0.05,1,0.05) # np.arange includes the lower bound, excludes upper bound\n",
    "# print(gammas)\n",
    "\n",
    "convergence_steps = []\n",
    "\n",
    "for g in range(len(gammas)):\n",
    "    policy, V, steps = value_iteration(gamma=gammas[g])\n",
    "    convergence_steps.append(steps)\n",
    "\n",
    "print(convergence_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(gammas, convergence_steps)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('# steps to convergence')\n",
    "plt.xticks(np.arange(0,1,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
